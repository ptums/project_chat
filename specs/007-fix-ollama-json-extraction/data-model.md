# Data Model: Fix Ollama JSON Extraction Bug

## Overview

This feature fixes a bug in the conversation indexing system. No new data entities are introduced. The fix involves improving how we extract and generate JSON from Ollama responses.

## Existing Entities (No Changes)

### `conversation_index` Table

**Purpose**: Stores indexed conversation metadata generated by Ollama.

**Fields** (existing):
- `conversation_id` (UUID, primary key)
- `version` (integer)
- `title` (text)
- `project` (text)
- `tags` (JSON array)
- `summary_short` (text)
- `summary_detailed` (text)
- `key_entities` (JSON object)
- `key_topics` (JSON array)
- `memory_snippet` (text)
- `created_at` (timestamp)

**Relationships**:
- One-to-one with `conversations` table via `conversation_id`

**Validation Rules**:
- All fields are required (enforced by `index_session` validation)
- `project` must be one of: "THN", "DAAS", "FF", "700B", "general"
- `tags` and `key_topics` must be arrays
- `key_entities` must be an object with optional `people`, `domains`, `assets` arrays

## Data Flow

### Current Flow (Before Fix)

1. User exits program (`/exit`) or switches projects
2. `save_current_conversation()` called
3. `index_session()` called with conversation ID
4. Ollama API called with prompt
5. Ollama returns response (may be JSON or markdown)
6. `extract_json_from_text()` tries to extract JSON
7. **BUG**: If no `{` found, raises `ValueError`
8. Indexing fails, exception propagates
9. Conversation may not be saved (depending on error handling)

### Fixed Flow (After Fix)

1. User exits program (`/exit`) or switches projects
2. `save_current_conversation()` called
3. `index_session()` called with conversation ID
4. Ollama API called with improved prompt (emphasizes JSON)
5. Ollama returns response (may be JSON or markdown)
6. **Enhanced extraction**:
   - Try to extract JSON from code blocks (```json ... ```)
   - Try to extract JSON from anywhere in response (search for `{`)
   - If extraction fails, try fallback generation from markdown
7. **Fallback generation**:
   - Parse markdown to extract key fields (title, project, tags, summary)
   - Generate valid JSON with extracted fields
   - Use conversation metadata as fallback values
8. **Graceful degradation**:
   - If all extraction/generation fails, log error but continue
   - Save conversation to database (indexing failure doesn't prevent save)
   - Return None or empty dict to indicate indexing failure
9. If JSON successfully extracted/generated:
   - Validate required fields
   - Upsert into `conversation_index` table

## Data Transformations

### Markdown to JSON Mapping

When fallback generation is needed, parse markdown structure:

| Markdown Pattern | JSON Field | Example |
|-----------------|------------|---------|
| `**Title:** text` or `* Title: text` | `title` | "Building Custom Mattermost Plugin" |
| `**Project:** text` or `* Project: text` | `project` | "THN" |
| `**Tags:** [tag1, tag2]` or `* Tags: tag1, tag2` | `tags` | `["mattermost", "plugin"]` |
| Paragraphs after `**Summary:**` or `* Summary:` | `summary_short`, `summary_detailed` | Extracted text |
| `**Key Entities:**` sections | `key_entities` | Parsed structure |
| `**Key Topics:**` lists | `key_topics` | Array of topics |

### Default Values

If markdown parsing fails to extract a field, use defaults:

- `title`: Use conversation title from `conversations` table
- `project`: Use conversation project from `conversations` table
- `tags`: Empty array `[]`
- `summary_short`: "Conversation indexed (fallback generation)"
- `summary_detailed`: "Full details unavailable due to indexing format issue"
- `key_entities`: Empty object `{"people": [], "domains": [], "assets": []}`
- `key_topics`: Empty array `[]`
- `memory_snippet`: "See conversation for details"

## State Transitions

### Indexing State Machine

```
[Conversation Created]
    ↓
[User Exits/Switches Project]
    ↓
[Indexing Attempt]
    ↓
    ├─→ [JSON Extraction Success] → [Validation] → [Upsert to DB] → [Success]
    │
    ├─→ [JSON Extraction Fails] → [Fallback Generation]
    │                                   ↓
    │                              [Markdown Parsing]
    │                                   ↓
    │                              [JSON Generation] → [Validation] → [Upsert to DB] → [Success]
    │
    └─→ [All Methods Fail] → [Log Error] → [Save Conversation] → [Indexing Failed, Conversation Saved]
```

## Constraints

1. **Backward Compatibility**: Must not break existing successful indexing flows
2. **Data Integrity**: Generated JSON must pass validation (all required fields present)
3. **Graceful Degradation**: Conversation save must succeed even if indexing fails
4. **Performance**: Extraction and generation must complete quickly (<500ms for fallback)

